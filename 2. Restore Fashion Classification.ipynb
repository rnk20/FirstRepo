{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Restoring the Model\n",
    "\n",
    "Code for Defining the DataFlow Graph will remain same except there will be no training of data so no optimizing sessions will be there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 200\n",
    "img_width = 200\n",
    "num_channels = 3\n",
    "num_classes = 5\n",
    "img_size_flat = 200*200*3\n",
    "\n",
    "filter_size1 = 11\n",
    "num_filters1 = 32\n",
    "\n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "filter_size3 = 2\n",
    "num_filters3 = 64\n",
    "#x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "\n",
    "#x_image = tf.reshape(x, [-1, img_height, img_width, num_channels], name='x_image')\n",
    "\n",
    "x_image = tf.placeholder(tf.float32, shape=[None, img_height, img_width, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name= 'y_true')\n",
    "\n",
    "y_true_cls = tf.argmax(y_true, axis = 1, name='y_true_cls')\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([filter_size1, filter_size1, num_channels, num_filters1], stddev=0.05)),\n",
    "    'h2': tf.Variable(tf.truncated_normal([filter_size2, filter_size2, 32, num_filters2], stddev=0.05)),\n",
    "    'newh1': tf.Variable(tf.truncated_normal([filter_size3, filter_size3, 32, num_filters3], stddev=0.05)),\n",
    "    'h3': tf.Variable(tf.truncated_normal([7*7*64, 7*7*64],stddev=0.05)),\n",
    "    'newh2': tf.Variable(tf.truncated_normal([7*7*64, 7*7*64],stddev=0.05)),\n",
    "    'newh3': tf.Variable(tf.truncated_normal([7*7*64, 1024],stddev=0.05)),\n",
    "    'out': tf.Variable(tf.truncated_normal([1024, 5],stddev=0.05))\n",
    "\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.05, shape=[num_filters1])),\n",
    "    'b2': tf.Variable(tf.constant(0.05, shape=[num_filters2])),\n",
    "    'newb1': tf.Variable(tf.constant(0.05, shape=[num_filters3])),\n",
    "    'b3': tf.Variable(tf.constant(0.05, shape=[7*7*64])),\n",
    "    'newb2': tf.Variable(tf.constant(0.05, shape=[7*7*64])),\n",
    "    'newb3': tf.Variable(tf.constant(0.05, shape=[1024])),\n",
    "    'out': tf.Variable(tf.constant(0.05,shape=[5]))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 50, 50, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 25, 25, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv1 = tf.nn.conv2d(input=x_image, filter= weights['h1'], strides=[1,4,4,1], padding='SAME') \n",
    "bias_add1 = tf.nn.bias_add(conv1, biases['b1'])\n",
    "relu1 = tf.nn.relu(bias_add1)\n",
    "pool1 = tf.nn.max_pool(value=relu1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "print(conv1)\n",
    "print(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 25, 25, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 13, 13, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv2 = tf.nn.conv2d(input=pool1, filter= weights['h2'], strides=[1,1,1,1], padding='SAME') \n",
    "bias_add2 = tf.nn.bias_add(conv2, biases['b2'])\n",
    "pool2 = tf.nn.max_pool(value=bias_add2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "relu2 = tf.nn.relu(pool2)\n",
    "print(conv2)\n",
    "print(pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_2:0\", shape=(?, 13, 13, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv3 = tf.nn.conv2d(input=relu2, filter= weights['newh1'], strides=[1,1,1,1], padding='SAME') \n",
    "bias_add3 = tf.nn.bias_add(conv3, biases['newb1'])\n",
    "pool3 = tf.nn.max_pool(value=bias_add3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "relu3 = tf.nn.relu(pool3)\n",
    "print(conv3)\n",
    "print(pool3)\n",
    "print(relu3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 3136) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2_flat = tf.reshape(relu3, [-1, 7*7*64])\n",
    "pool2_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 3136) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer = tf.add(tf.matmul(pool2_flat, weights['h3']), biases['b3'], name='fc_layer')\n",
    "relu4 = tf.nn.relu(fc_layer)\n",
    "relu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_1 = tf.add(tf.matmul(relu4, weights['newh2']), biases['newb2'], name='fc_layer_1')\n",
    "relu5 = tf.nn.relu(fc_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer_l = tf.add(tf.matmul(relu5, weights['newh3']), biases['newb3'], name='fc_layer_l')\n",
    "relu6 = tf.nn.relu(fc_layer_l)\n",
    "relu6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout/mul:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = tf.nn.dropout(relu6, 0.25)\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer2 = tf.add(tf.matmul(dropout, weights['out']), biases['out'], name='fc_layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(fc_layer2, axis=1, name='y_pred_cls')\n",
    "y_pred_prbl = tf.nn.softmax(fc_layer2, name='y_pred_prbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-70e68f9c3d23>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=fc_layer2,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy, name='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3, name='optimizer').minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Defining DataFlow Graph ends here.\n",
    "### Now we will restore the Trained Weights\n",
    "\n",
    "\n",
    "\n",
    "## Restoring Trained Model \n",
    "\n",
    "Weights for the following Variables are now restored for testing:\n",
    "\n",
    "1. weights \n",
    "2. biases\n",
    "\n",
    "Trained Weights for these variables will be used to test the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "model_path = \"Jack Class new/JC\"\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Test Data \n",
    "\n",
    "Test Data Contains 50 (200x200) sized images for each class.\n",
    "\n",
    "Total Number of Test Data = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 200, 200, 3)\n",
      "(250, 5)\n",
      "33_Skirts_resized.jpg\n",
      "[0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "classes = ['Jackets', 'Jeans', 'Skirts', 'Sunglasses', 'Tops']\n",
    "\n",
    "cwd = os.getcwd()\n",
    "list_files = os.listdir('/home/shresth/tust/Jeans/')\n",
    "\n",
    "y_true_batch = []\n",
    "for nm in list_files:\n",
    "    for cl in classes:\n",
    "            if cl in nm:\n",
    "                one_hot = [0., 0., 0., 0., 0.]\n",
    "                one_hot[classes.index(cl)] = 1.\n",
    "                y_true_batch.append(one_hot)\n",
    "y_true_batch = np.array(y_true_batch)\n",
    "\n",
    "test = [cv2.imread('/home/shresth/tust/Jeans/' + i) for i in list_files]\n",
    "test = np.array(test)\n",
    "print(test.shape)\n",
    "print(y_true_batch.shape)\n",
    "#list_files[0]\n",
    "print(list_files[0])\n",
    "print(y_true_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tensorflow DataFlow Graph\n",
    "\n",
    "85.6% accuracy is obtained from the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sess.run(accuracy, feed_dict={x_image: test, y_true: y_true_batch})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
